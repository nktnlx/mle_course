{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Neural Networks Optimization","metadata":{}},{"cell_type":"markdown","source":"## Tasks","metadata":{}},{"cell_type":"markdown","source":"### Task 1","metadata":{}},{"cell_type":"markdown","source":"Code a function `create_model` that returns a fully connected neural network with two layers.  \nThe input should be 100 numbers, the output should be 1, and the middle layer should have 10 neurons.  \nUse `ReLU` as the non-linearity. Use `nn.Sequential` and pass the layers as a sequence.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n\ndef create_model():\n    model = nn.Sequential(\n        nn.Linear(100, 10),  \n        nn.ReLU(),           \n        nn.Linear(10, 1)     \n    )\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T05:18:13.615962Z","iopub.execute_input":"2025-03-09T05:18:13.616294Z","iopub.status.idle":"2025-03-09T05:18:15.096734Z","shell.execute_reply.started":"2025-03-09T05:18:13.616270Z","shell.execute_reply":"2025-03-09T05:18:15.095818Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"model = create_model()\nsample_input = torch.randn(1, 100)\noutput = model(sample_input)\n\nprint(f'Input shape: {sample_input.shape}')\nprint(f'Output shape: {output.shape}')\nprint(f'Output value: {output.item():.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T05:18:15.097705Z","iopub.execute_input":"2025-03-09T05:18:15.098032Z","iopub.status.idle":"2025-03-09T05:18:15.105621Z","shell.execute_reply.started":"2025-03-09T05:18:15.098001Z","shell.execute_reply":"2025-03-09T05:18:15.104667Z"}},"outputs":[{"name":"stdout","text":"Input shape: torch.Size([1, 100])\nOutput shape: torch.Size([1, 1])\nOutput value: 0.0819\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Task 2","metadata":{}},{"cell_type":"markdown","source":"Code a function `train`. It should take as input a neural network, a dataloader, an optimizer, and a loss function.  \nIt should have the following signature: `def train(model: nn.Module, data_loader: DataLoader, optimizer: Optimizer, loss_fn)`:\n\nInside the function, do the following steps:\n\n1. Set the model to training mode.\n\n2. Iterate through the dataloader.\n\n3. On each iteration:\n    - Zero the gradients using the optimizer\n    - Make a forward pass\n    - Calculate the error\n    - Make a backward pass\n    - Print the error on the current batch with precision up to 5 decimal places (only the number)\n    - Make an optimization step.\n\nThe function should return the average error during the pass through the dataloader.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Optimizer\n\n\ndef train(model: nn.Module, data_loader: DataLoader, optimizer: Optimizer, loss_fn):\n    model.train()\n    \n    total_loss = 0.0\n    for inputs, targets in data_loader:        \n        optimizer.zero_grad()\n        outputs = model(inputs)  # forward pass\n        loss = loss_fn(outputs, targets)\n        loss.backward()\n        print(f'{loss.item():.5f}')\n        optimizer.step()  # optimization\n        total_loss += loss.item()  # adding current loss to total loss\n    \n    avg_loss = total_loss / len(data_loader)\n    \n    return avg_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T05:18:15.107203Z","iopub.execute_input":"2025-03-09T05:18:15.107460Z","iopub.status.idle":"2025-03-09T05:18:15.121874Z","shell.execute_reply.started":"2025-03-09T05:18:15.107432Z","shell.execute_reply":"2025-03-09T05:18:15.120994Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\nfrom torch.optim import SGD\n\n\nnum_samples = 500\ninput_dim = 100\n\n# creating data\nX = torch.randn(num_samples, input_dim)\nweights = torch.randn(input_dim, 1) * 0.1\ny = torch.matmul(X, weights) + torch.randn(num_samples, 1) * 0.1\n\n# creating dataset and dataloader\ndataset = TensorDataset(X, y)\ndata_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n\n# creating model, loss function, and optimizer\nmodel = create_model()\nloss_fn = nn.MSELoss()\noptimizer = SGD(model.parameters(), lr=0.01)\n\n# train model\nprint(\"Training model:\")\navg_loss = train(model, data_loader, optimizer, loss_fn)\nprint(f\"\\nAverage loss: {avg_loss:.5f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T05:18:15.122879Z","iopub.execute_input":"2025-03-09T05:18:15.123105Z","iopub.status.idle":"2025-03-09T05:18:15.940431Z","shell.execute_reply.started":"2025-03-09T05:18:15.123088Z","shell.execute_reply":"2025-03-09T05:18:15.939558Z"}},"outputs":[{"name":"stdout","text":"Training model:\n1.09693\n1.35616\n1.08373\n1.25230\n1.34806\n1.14654\n0.97326\n1.54920\n\nAverage loss: 1.22577\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### Task 3","metadata":{}},{"cell_type":"markdown","source":"Code a function `evaluate`. It should take as input a neural network, a dataloader, and a loss function.  \nIt should have the following signature: `def evaluate(model: nn.Module, data_loader: DataLoader, loss_fn)`:\n\nInside the function, do the following steps:\n\n1. Set the model to inference mode (evaluation)\n\n2. Iterate through the dataloader\n\n3. On each iteration:\n    - Make a forward pass\n    - Calculate the error.\n\nThe function should return the average error during the pass through the dataloader.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\n\ndef evaluate(model: nn.Module, data_loader: DataLoader, loss_fn):\n    model.eval()\n    \n    total_loss = 0.0\n    with torch.no_grad():  # disable gradients calc to make function work faster\n        for inputs, targets in data_loader:\n            outputs = model(inputs)  # forward pass\n            loss = loss_fn(outputs, targets)\n            total_loss += loss.item()\n    \n    avg_loss = total_loss / len(data_loader)\n    \n    return avg_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T05:18:15.941127Z","iopub.execute_input":"2025-03-09T05:18:15.941406Z","iopub.status.idle":"2025-03-09T05:18:15.946816Z","shell.execute_reply.started":"2025-03-09T05:18:15.941389Z","shell.execute_reply":"2025-03-09T05:18:15.945900Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"evaluate(model, data_loader, loss_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T05:18:15.948276Z","iopub.execute_input":"2025-03-09T05:18:15.948657Z","iopub.status.idle":"2025-03-09T05:18:15.973525Z","shell.execute_reply.started":"2025-03-09T05:18:15.948629Z","shell.execute_reply":"2025-03-09T05:18:15.972776Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"1.1299102902412415"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}