{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Convolutional Neural Networks - Part II","metadata":{}},{"cell_type":"markdown","source":"## Tasks","metadata":{}},{"cell_type":"markdown","source":"### Task 1","metadata":{}},{"cell_type":"markdown","source":"Code a function `get_normalize` that will take a tensor with features of objects from some dataset with images and will return the per-channel mean and per-channel standard deviation.   \nIt is guaranteed that the matrix will have size \\[N, C, H, W\\], where:\n- `N` is the number of objects,\n- `C` is the number of channels,\n- `H`, `W` are the dimensions of the images.\n\nYou need to return a tuple of two tensors of length `C`.  \nYour function should have the following signature: `def get_normalize(features: torch.Tensor)`","metadata":{}},{"cell_type":"code","source":"import torch\n\n\ndef get_normalize(features: torch.Tensor):\n    mean = torch.mean(features, dim=(0, 2, 3))\n    std = torch.std(features, dim=(0, 2, 3))\n    return mean, std","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T05:36:09.729547Z","iopub.execute_input":"2025-03-15T05:36:09.729952Z","iopub.status.idle":"2025-03-15T05:36:11.680194Z","shell.execute_reply.started":"2025-03-15T05:36:09.729903Z","shell.execute_reply":"2025-03-15T05:36:11.679067Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"N, C, H, W = 10, 3, 32, 32\nfeatures = torch.randn(N, C, H, W)\n\nmean, std = get_normalize(features)\n\nprint('Mean:', mean)\nprint('Std:', std)\nprint('Mean shape:', mean.shape)\nprint('Std shape:', std.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T05:36:11.681577Z","iopub.execute_input":"2025-03-15T05:36:11.681991Z","iopub.status.idle":"2025-03-15T05:36:11.694637Z","shell.execute_reply.started":"2025-03-15T05:36:11.681964Z","shell.execute_reply":"2025-03-15T05:36:11.693492Z"}},"outputs":[{"name":"stdout","text":"Mean: tensor([-0.0095, -0.0103, -0.0054])\nStd: tensor([0.9910, 0.9868, 1.0093])\nMean shape: torch.Size([3])\nStd shape: torch.Size([3])\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Task 2","metadata":{}},{"cell_type":"markdown","source":"Code a function `get_augmentations` that will return ready-made augmentations for the training set and for the test set. It should have the following signature: `def get_augmentations(train: bool = True) -> T.Compose`  \n\nApply the following augmentations:\n- Change the image size to make it 224 by 224 pixels (for both training and test sets).\n- Apply some augmentations from those we studied in class (only for training).\n- Convert the image to a tensor.\n- Apply normalization for the `CIFAR10` dataset.","metadata":{}},{"cell_type":"code","source":"import torchvision.transforms as T\n\n\ndef get_augmentations(train: bool = True) -> T.Compose:\n    # values specific for CIFAR10 dataset\n    means = (0.49139968, 0.48215841, 0.44653091)\n    stds = (0.24703223, 0.24348513, 0.26158784)\n\n    if train:\n        return T.Compose([\n            T.Resize((224, 224)),\n            T.RandomHorizontalFlip(),\n            T.RandomRotation(degrees=15),\n            T.RandomCrop(size=224, padding=4),\n            T.ToTensor(),\n            T.Normalize(means, stds)\n        ])\n    else:\n        return T.Compose([\n            T.Resize((224, 224)),\n            T.ToTensor(),\n            T.Normalize(means, stds)\n        ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T05:36:11.696739Z","iopub.execute_input":"2025-03-15T05:36:11.697061Z","iopub.status.idle":"2025-03-15T05:36:12.871359Z","shell.execute_reply.started":"2025-03-15T05:36:11.697036Z","shell.execute_reply":"2025-03-15T05:36:12.870467Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_transforms = get_augmentations(train=True)\ntest_transforms = get_augmentations(train=False)\n\nprint('Train Transforms:', train_transforms)\nprint('Test Transforms:', test_transforms)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T05:36:12.872585Z","iopub.execute_input":"2025-03-15T05:36:12.873025Z","iopub.status.idle":"2025-03-15T05:36:12.878895Z","shell.execute_reply.started":"2025-03-15T05:36:12.872995Z","shell.execute_reply":"2025-03-15T05:36:12.877771Z"}},"outputs":[{"name":"stdout","text":"Train Transforms: Compose(\n    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n    RandomHorizontalFlip(p=0.5)\n    RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n    RandomCrop(size=(224, 224), padding=4)\n    ToTensor()\n    Normalize(mean=(0.49139968, 0.48215841, 0.44653091), std=(0.24703223, 0.24348513, 0.26158784))\n)\nTest Transforms: Compose(\n    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n    ToTensor()\n    Normalize(mean=(0.49139968, 0.48215841, 0.44653091), std=(0.24703223, 0.24348513, 0.26158784))\n)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### Task 3","metadata":{}},{"cell_type":"markdown","source":"Code a function `predict`. It should take as input a neural network, a dataloader, and torch.device.  \nIt should have the following signature: `def predict(model: nn.Module, loader: DataLoader, device: torch.device)`  \n\nInside the function, take the following steps:\n- Create an empty list to store predictions.\n- Iterate through the dataloader.\n- On each iteration, do a forward pass for the batch, calculate the classes as argmax on the neural network output (logits), add the tensor with predictions to the list.\n- Concatenate all predictions and return this tensor of length N, according to the number of objects in the dataset.\n- Your function should return a tensor with classes.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n\n\ndef predict(model: nn.Module, loader: DataLoader, device: torch.device):\n    predictions = []\n    model.eval()\n\n    with torch.no_grad():\n        for batch in loader:\n            if isinstance(batch, (list, tuple)):\n                x = batch[0]\n            else:\n                x = batch\n            \n            x = x.to(device)\n            outputs = model(x)\n            pred_classes = torch.argmax(outputs, dim=1)\n            \n            predictions.append(pred_classes)\n    \n    all_predictions = torch.cat(predictions)\n    \n    return all_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T05:36:12.880267Z","iopub.execute_input":"2025-03-15T05:36:12.880535Z","iopub.status.idle":"2025-03-15T05:36:12.901920Z","shell.execute_reply.started":"2025-03-15T05:36:12.880512Z","shell.execute_reply":"2025-03-15T05:36:12.900838Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Dummy model for testing\nclass DummyModel(nn.Module):\n    def __init__(self, input_size, num_classes):\n        super().__init__()\n        self.linear = nn.Linear(input_size, num_classes)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\ninput_size = 10\nnum_classes = 5\nbatch_size = 32\nnum_samples = 100\n\nmodel = DummyModel(input_size, num_classes)\ndata = torch.randn(num_samples, input_size)\nlabels = torch.randint(0, num_classes, (num_samples,))\ndataset = torch.utils.data.TensorDataset(data, labels)\nloader = DataLoader(dataset, batch_size=batch_size)\ndevice = torch.device('cpu') \n\n# Get predictions\npredicted_classes = predict(model, loader, device)\n\nprint('Predicted Classes:', predicted_classes)\nprint('Predicted Classes Shape:', predicted_classes.shape)\nprint('Predicted classes length:', len(predicted_classes))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T05:36:12.902976Z","iopub.execute_input":"2025-03-15T05:36:12.903286Z","iopub.status.idle":"2025-03-15T05:36:12.923877Z","shell.execute_reply.started":"2025-03-15T05:36:12.903257Z","shell.execute_reply":"2025-03-15T05:36:12.922290Z"}},"outputs":[{"name":"stdout","text":"Predicted Classes: tensor([4, 3, 0, 4, 1, 2, 2, 2, 4, 2, 3, 4, 0, 1, 0, 3, 0, 2, 1, 0, 2, 2, 1, 2,\n        0, 2, 4, 4, 4, 4, 1, 4, 4, 3, 0, 1, 2, 4, 0, 1, 2, 1, 2, 1, 0, 1, 3, 4,\n        2, 4, 3, 3, 4, 4, 2, 4, 3, 0, 4, 2, 1, 4, 3, 3, 3, 1, 2, 2, 4, 4, 2, 0,\n        0, 4, 0, 1, 1, 4, 3, 1, 2, 3, 0, 1, 3, 2, 3, 3, 0, 4, 2, 0, 1, 1, 3, 3,\n        2, 1, 1, 4])\nPredicted Classes Shape: torch.Size([100])\nPredicted classes length: 100\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"### Task 4","metadata":{}},{"cell_type":"markdown","source":"Code a function `predict_tta`. It should accept a neural network, a DataLoader, a torch.device, and the number of iterations over the DataLoader. It should have the following signature: `def predict_tta(model: nn.Module, loader: DataLoader, device: torch.device, iterations: int = 2)`  \n\nInside the function, take the following steps:\n-   Start a loop for the number of iterations.\n-   Inside the loop, iterate through the DataLoader.\n-   Record the model's responses (not classes, but raw neural network outputs) into one large tensor of size \\[N, C\\], where C is the number of classes, and N is the number of objects in the dataset (that is, we must have a vector of neural network outputs, logits, for each object).\n-   Make one huge tensor of size \\[N, C, iterations\\] from these tensors, average it over the iterations so that its size becomes \\[N, C\\].\n-   Then predict the classes for the objects from this tensor as argmax, return them from the function.\n-   Your function should return a tensor with classes. Don't forget to switch the model to application mode and use a decorator to disable gradient calculation.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n\n\ndef predict_tta(model: nn.Module, loader: DataLoader, device: torch.device, iterations: int = 2) -> torch.Tensor:\n    predictions = []\n    model.eval()\n\n    with torch.no_grad(): \n        for _ in range(iterations):\n            single_iteration_predictions = []\n            for images, _ in loader:\n                images = images.to(device)\n                outputs = model(images)\n                single_iteration_predictions.append(outputs)\n            predictions.append(torch.vstack(single_iteration_predictions)) \n\n    predictions = torch.stack(predictions, dim=2)  \n    averaged_predictions = torch.mean(predictions, dim=2)  \n    predicted_classes = torch.argmax(averaged_predictions, dim=1)\n\n    return predicted_classes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T05:36:12.925178Z","iopub.execute_input":"2025-03-15T05:36:12.925571Z","iopub.status.idle":"2025-03-15T05:36:12.932788Z","shell.execute_reply.started":"2025-03-15T05:36:12.925533Z","shell.execute_reply":"2025-03-15T05:36:12.931689Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Dummy Model for testing\nclass DummyModel(nn.Module):\n    def __init__(self, input_size, num_classes):\n        super().__init__()\n        self.linear = nn.Linear(input_size, num_classes)\n\n    def forward(self, x):\n        return self.linear(x)\n\n# data for testing\nbatch_size = 16\nnum_samples = 100 \ninput_size = 28 * 28 \nnum_classes = 10\niterations = 3\n\nimages = torch.randn(num_samples, input_size)\nlabels = torch.randint(0, num_classes, (num_samples,))\n\ndataset = TensorDataset(images, labels)  # Create a dataset\nloader = DataLoader(dataset, batch_size=batch_size)\n\ndevice = torch.device('cpu') \nmodel = DummyModel(input_size, num_classes).to(device)\n\n\npredicted_classes = predict_tta(model, loader, device, iterations)\n\nprint(f'Predicted classes shape: {predicted_classes.shape}')\nprint(f'Predicted classes type: {predicted_classes.dtype}')\nprint(f'Predicted classes: {predicted_classes}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T05:36:12.935298Z","iopub.execute_input":"2025-03-15T05:36:12.935623Z","iopub.status.idle":"2025-03-15T05:36:12.967572Z","shell.execute_reply.started":"2025-03-15T05:36:12.935595Z","shell.execute_reply":"2025-03-15T05:36:12.966515Z"}},"outputs":[{"name":"stdout","text":"Predicted classes shape: torch.Size([100])\nPredicted classes type: torch.int64\nPredicted classes: tensor([4, 5, 6, 8, 6, 7, 9, 3, 8, 5, 1, 7, 1, 2, 1, 1, 0, 1, 8, 6, 4, 6, 7, 6,\n        0, 2, 2, 4, 4, 1, 3, 1, 5, 6, 5, 2, 5, 1, 5, 0, 2, 3, 5, 3, 3, 9, 4, 9,\n        0, 9, 6, 0, 7, 8, 1, 5, 7, 6, 9, 7, 8, 9, 4, 1, 3, 8, 4, 4, 0, 5, 8, 0,\n        8, 8, 9, 7, 3, 3, 6, 8, 2, 9, 1, 3, 4, 6, 5, 2, 3, 9, 3, 3, 5, 0, 9, 8,\n        7, 3, 1, 3])\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}